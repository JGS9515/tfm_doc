\chapter{Conclusiones}

\section{Resumen del trabajo desarrollado}
Este Trabajo Fin de Máster ha abordado el problema de la detección de anomalías en series temporales mediante arquitecturas basadas en Redes Neuronales de Impulsos (SNN), proponiendo una extensión híbrida SNN-CNN optimizada automáticamente con Optuna. Se utilizaron dos datasets de características diferentes: IOPS (altamente desbalanceado, 1.92\% anomalías) y CalIt2 (moderadamente balanceado, 24.80\% anomalías), aplicando un pipeline de preprocesamiento que incluye cuantización dinámica por cuantiles expandidos, expansión de etiquetas para mitigar el desbalanceo temporal, y segmentación en ventanas de longitud T=250. La arquitectura propuesta (A--B--C) integra una capa convolucional parametrizable con kernels gaussiano, laplaciano, mexican hat y box, junto con modos de fusión direct, weighted\_sum y max. Se empleó F1-score como métrica principal de evaluación, comparando contra el modelo SNN base (A--B) y baselines de TSFEDL. La motivación energética del trabajo se fundamenta en el potencial de las SNNs para computación neuromórfica eficiente, aprovechando la sparsity inherente a los patrones de impulsos discretos.

\section{Grado de cumplimiento de los objetivos}
% Reutilizar la lista de objetivos del Capítulo 2 y marcar su estado.
\begin{table}[htbp]
    \centering
    \small
    \begin{tabular}{p{0.62\textwidth}p{0.28\textwidth}}
        \hline\hline
        \textbf{Objetivo} & \textbf{Estado (Sí/Parcial/No)} \\
        \hline
        O1: Revisión bibliográfica de modelos de Redes Neuronales de Impulsos (SNNs) y su aplicación en detección de anomalías y mantenimiento predictivo. & Sí \\
        O2: Diseño y desarrollo de arquitecturas de SNNs optimizadas para la detección de anomalías en datos de sensores industriales. & Sí \\
        O3: Implementación de modelos de SNNs sostenibles que minimicen el consumo energético sin sacrificar la precisión. & Parcial \\
        O4: Validación de los modelos desarrollados mediante experimentación en conjuntos de datos reales de mantenimiento predictivo. & Sí \\
        O5: Comparación de la eficiencia energética y el rendimiento predictivo frente a modelos tradicionales de detección de anomalías. & Sí \\ 
        % Añadir otros si hubo (p.ej. integración MLOps con W\&B)
        \hline\hline
    \end{tabular}
    \caption{Resumen del grado de cumplimiento de los objetivos planteados.}
    \label{tab:objetivos-cumplimiento}
\end{table}


\begin{itemize}
    \item \textbf{Objetivo más destacado}: O2 (Diseño y desarrollo de arquitecturas optimizadas) - Se logró desarrollar exitosamente una arquitectura híbrida SNN-CNN con optimización bayesiana automatizada mediante Optuna TPE, ejecutando 100 trials por configuración y logrando convergencia estable de los hiperparámetros. La optimización automatizada fue una metodología clave que permitió explorar sistemáticamente el espacio de parámetros neuronales y convolucionales.
    \item \textbf{Objetivo parcialmente cumplido}: O3 (Implementación sostenible) - Se desarrolló el análisis teórico de eficiencia mediante estimación de MACs bajo supuestos de sparsity, pero no se pudo validar empíricamente en hardware neuromórfico debido a limitaciones de acceso.
    \item \textbf{Acciones compensatorias}: Se implementó experiment tracking con Weights \& Biases, almacenamiento estructurado de configuraciones, y análisis detallado de complejidad computacional que sienta bases para evaluación energética futura.
\end{itemize}

\section{Principales contribuciones}
% Lista breve de aportaciones técnicas / metodológicas.
\begin{enumerate}
    \item Propuesta e implementación de una arquitectura híbrida SNN-CNN con capa convolucional parametrizable (kernels gaussiano, laplaciano, mexican hat, box) y modos de fusión (direct, weighted\_sum, max), desarrollada mediante estrategia sistemática de optimización bayesiana (Optuna TPE) sobre parámetros neuronales (threshold, decay), de plasticidad (nu1, nu2) y de la capa convolucional.
    \item Pipeline de preprocesamiento reproducible: cuantización dinámica por cuantiles expandidos (parámetros \(a\), \(r\)), expansión de etiquetas (\texttt{expansion}) para mejorar cobertura de eventos anómalos y segmentación temporal en ventanas de longitud \(T\).
    \item Comparativa empírica contra el modelo base (SNN A--B) y contra baselines de \texttt{TSFEDL} mostrando que, aunque los modelos TSFEDL superan en rendimiento (F1=0.436 vs 0.277 en IOPS, F1=0.704 vs 0.417 en CalIt2), las SNN mantienen ventajas en eficiencia y potencial para computación neuromórfica.
    \item Esquema analítico preliminar de complejidad computacional (estimación de MACs bajo supuesto de sparsity), sentando bases para evaluación energética futura en hardware neuromórfico.
    \item Integración de experiment tracking con Weights \& Biases y almacenamiento estructurado de configuraciones (\texttt{best\_config.json}) para reproducibilidad.
\end{enumerate}

\section{Discusión de resultados}
Los resultados obtenidos del análisis experimental evidencian que:
\begin{itemize}
    \item La capa convolucional mejora significativamente el F1-score respecto a la SNN base en datasets altamente desbalanceados como IOPS (4.6x, de 0.060 a 0.277), aunque con rendimiento dependiente del número de neuronas (n\_100 > n\_200 > n\_400). En CalIt2 mantiene robustez con F1-scores estables (0.416-0.417) independientemente del número de neuronas (100-400).
    \item El modo de procesamiento \texttt{direct} fue consistentemente seleccionado por Optuna como óptimo en CalIt2, junto con kernels \texttt{mexican\_hat} y \texttt{gaussian} con tamaños 5-7, indicando preferencia por suavizado espacial. En contraste, IOPS favoreció \texttt{weighted\_sum} y \texttt{max} con kernels \texttt{laplacian} y \texttt{mexican\_hat}, sugiriendo necesidad de detección de bordes para anomalías de sistema más bruscas.
    \item Los parámetros \texttt{threshold} (rango [-66.8, -67.7]) y \texttt{decay} (rango [73.6-139.8]) emergen como los más influyentes según las optimizaciones de Optuna, seguidos de \texttt{kernel\_size} y \texttt{sigma}, confirmando la importancia de la dinámica neuronal LIF.
    \item Los modelos TSFEDL (OhShuLih, KhanZulfiqar, ZhengZhenyu) superan consistentemente a las SNN en ambos datasets, con diferencias más pronunciadas en IOPS debido al extremo desbalanceo que las SNN no logran manejar efectivamente.
\end{itemize}

\subsection{Interpretación técnica}
Los patrones observados en la selección de kernels sugieren preferencias específicas según las características del dataset:
En CalIt2, Optuna seleccionó consistentemente kernels \texttt{mexican\_hat} y \texttt{gaussian} con tamaños intermedios (5-7), indicando que el suavizado espacial y la detección de transiciones graduales son más efectivos que la detección de bordes abruptos para este tipo de señales de flujo de edificios. El kernel \texttt{mexican\_hat}, al combinar un componente central positivo con anillos negativos, permite detectar cambios locales preservando el contexto temporal, mientras que el kernel \texttt{gaussian} atenúa el ruido impulsivo manteniendo las características principales de la señal.

\subsection{Implicaciones prácticas}
El modelo híbrido desarrollado presenta potencial para aplicaciones reales de mantenimiento predictivo y monitorización IoT, especialmente en entornos con restricciones energéticas. Los tiempos de inferencia de 12-15 ms por ventana de 250 muestras permiten procesamiento en tiempo real, mientras que la arquitectura basada en impulsos discretos es inherentemente compatible con hardware neuromórfico de bajo consumo. En el contexto de mantenimiento predictivo, el alto recall observado (99.9\% en CalIt2) es crucial para evitar fallos no detectados, aunque la baja precisión requiere sistemas de post-procesado para reducir falsas alarmas.

El modelo híbrido es aplicable a escenarios de edge computing al reducir cómputo mediante sparsity, siempre que se complemente con:
\begin{itemize}
    \item Módulos ligeros de post-procesado para consolidar alertas.
    \item Ajustes de umbrales adaptativos según distribución reciente de actividad neuronal.
\end{itemize}

\section{Limitaciones y amenazas a la validez}
\subsection{Limitaciones experimentales}
\begin{itemize}
    \item \textbf{Particionado 50/50}: Falta de validación cruzada temporal podría introducir sesgos en generalización.
    \item \textbf{Estimación energética indirecta}: No se dispuso de medición real de consumo en hardware neuromórfico (solo estimaciones analíticas de MACs).
    \item \textbf{Escalabilidad multivariante}: Experimentos centrados principalmente en señales univariadas (o pocas variables); falta evaluación en entornos fuertemente multivariados.
    \item \textbf{GPU}: Uno de los motivos para seleccionar \texttt{BindsNET} fue la posibilidad de aprovechar aceleración GPU; sin embargo, la imposibilidad de disponer de una configuración estable de dicha aceleración (incompatibilidades de dependencias en Windows) incrementó la duración de los entrenamientos y restringió la amplitud de la exploración de hiperparámetros. Esto podría implicar que combinaciones óptimas no hayan sido completamente identificadas. No obstante, dado que todos los modelos se ejecutaron bajo condiciones homogéneas (CPU) y que el preprocesamiento fue uniforme, la validez interna de la comparación se mantiene. Futuros trabajos sobre un entorno Linux con soporte CUDA habilitado permitirán ampliar la búsqueda y evaluar la robustez frente a una exploración más exhaustiva.
\end{itemize}

\subsection{Amenazas a la validez}
\begin{itemize}
    \item \textbf{Interna}: Expansión de etiquetas podría inflar artificialmente el recall si no se aplica consistentemente en inferencia.
    \item \textbf{Externa}: Datasets (IOPS, CalIt2) pueden no representar toda la diversidad industrial (ciclos estacionales largos, variabilidad contextual).
    \item \textbf{Conclusión}: Comparaciones con TSFEDL limitadas a cuatro modelos específicos (OhShuLih, KhanZulfiqar, ZhengZhenyu, WeiXiaoyan), sin acceso a mediciones de consumo energético de los baselines.
\end{itemize}

\section{Conclusiones finales}
En síntesis, este trabajo ha demostrado que las arquitecturas híbridas SNN-CNN, aunque no superan consistentemente a los métodos de deep learning tradicionales en términos de F1-score, ofrecen un compromiso interesante entre rendimiento y eficiencia computacional. La arquitectura propuesta logró F1-scores de 0.417 en CalIt2, manteniéndose competitiva en datasets moderadamente balanceados, mientras que en IOPS mostró mejoras significativas respecto al modelo SNN base (4.6x) pero mantuvo limitaciones frente a métodos tradicionales en escenarios de desbalanceo extremo.

La optimización bayesiana con Optuna demostró ser una herramienta fundamental para la parametrización fina de arquitecturas SNN complejas, permitiendo explorar sistemáticamente el espacio de hiperparámetros neuronales y convolucionales. Los tiempos de inferencia de 12-15 ms por ventana posicionan al modelo como viable para aplicaciones de tiempo real en edge computing, especialmente cuando se despliegue en hardware neuromórfico dedicado donde las ventajas energéticas de la sparsity pueden ser plenamente aprovechadas.

La metodología desarrollada sienta bases sólidas para trabajos futuros en detección de anomalías con SNNs, proporcionando un pipeline reproducible de preprocesamiento, optimización y evaluación que puede ser extendido a otros dominios y arquitecturas neuromórficas más avanzadas.
Estos hallazgos apoyan la hipótesis de que la integración de mecanismos convolucionales y optimización sistemática reduce la brecha entre SNN y enfoques ANN tradicionales para detección de anomalías en series temporales.

\section{Trabajos futuros}
% Estructurar en líneas de investigación priorizadas.
\subsection{Optimización técnica}
\begin{itemize}
    \item \textbf{Validación cruzada temporal}: Implementar estrategias como rolling-origin o nested backtesting para robustecer la estimación de generalización.
    \item \textbf{Multiobjetivo}: Extender la optimización con Optuna a objetivos conjuntos (F1 y coste computacional/MACs), empleando algoritmos como NSGA-II.
    \item \textbf{Umbral adaptativo}: Introducir calibración dinámica (e.g. percentil 95 de actividad normal reciente) para reducir drift.
    \item \textbf{Codificaciones alternativas}: Evaluar codificación por tasa vs. latencia vs. rank-order para mejorar discriminabilidad temprana.
\end{itemize}

\subsection{Ampliación de dominios y robustez}
\begin{itemize}
    \item Incorporar datasets multivariantes industriales (vibración, temperatura, presión) y comparar rendimiento frente a modelos de atención temporal.
    \item Evaluar robustez frente a ruido sintético aditivo y drift de distribución (concept drift) aplicando técnicas de continual learning.
    \item Analizar explicabilidad: mapear contribución de patrones de spikes a decisiones (saliency sobre tiempos).
\end{itemize}

\subsection{Evaluación energética y despliegue neuromórfico}
\label{subsec:trabajo-futuro-neuromorfico}
Una línea prioritaria consiste en la ejecución del modelo en hardware neuromórfico dedicado para validar empíricamente las estimaciones de eficiencia:
\begin{itemize}
    \item \textbf{Plataformas candidatas}: Intel Loihi 2, SpiNNaker 2, BrainScaleS-2, chips basados en memristores emergentes.
    \item \textbf{Portado del modelo}: Conversión de parámetros LIF y topología a formato compatible (e.g. NxSDK / Lava para Loihi), sustituyendo operaciones convolucionales por proyecciones locales o \textit{compartment groups}.
    \item \textbf{Métricas energéticas}: Joules por inferencia, mW promedio, latencia por ventana \(T\), escalabilidad en número de neuronas vs. consumo.
\end{itemize}

\subsection{Integración MLOps y ciclo de vida}
\begin{itemize}
    \item Versionado de datasets y features con herramientas como DVC.
    \item Monitorización continua de drift y re-entrenamiento disparado por degradación de F1/recall.
    \item Empaquetado en contenedores ligeros o despliegue sobre microcontroladores con toolchains específicos (TinyML + SNN surrogate).
\end{itemize}

\subsection{Líneas exploratorias adicionales}
\begin{itemize}
    \item \textbf{Aprendizaje supervisado híbrido}: Incorporar cabezas clasificadoras ANN ligeras sobre representaciones SNN para comparar supervisado vs. autoorganizado.
    \item \textbf{Plasticidad avanzada}: Evaluar reglas triplet-STDP, homeostasis sináptica y modulación dopaminérgica para estabilizar el aprendizaje continuo.
    \item \textbf{Reducción de dimensionalidad previa}: Análisis de PCA/autoencoders para reducir ruido antes de la codificación a spikes.
\end{itemize}
