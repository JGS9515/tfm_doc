\chapter*{Resumen}
\addcontentsline{toc}{chapter}{Resumen}
\label{chap:resumen}


Detectar anomalías en series temporales es un problema complejo que afecta a muchos sectores industriales: desde redes informáticas hasta infraestructuras críticas que requieren mantenimiento predictivo. Los métodos tradicionales funcionan, pero tienen limitaciones importantes de eficiencia energética y escalabilidad, sobre todo cuando hablamos de edge computing o dispositivos con recursos limitados.

Este Trabajo Fin de Máster aborda el desarrollo y optimización de una arquitectura híbrida SNN-CNN (Spiking Neural Network - Convolutional Neural Network) para detectar anomalías en series temporales. El foco está en la sostenibilidad computacional y la eficiencia energética. Las Redes Neuronales de Impulsos (SNNs) son interesantes porque imitan mejor el funcionamiento del cerebro biológico, y en teoría pueden ser más eficientes energéticamente gracias a la naturaleza dispersa (sparse) de los impulsos discretos.

La solución propuesta parte de una arquitectura SNN base (A--B) y añade una capa convolucional optimizable (A--B--C) que trabaja con diferentes kernels parametrizables (gaussiano, laplaciano, mexican hat, box) y varios modos de procesamiento (direct, weighted\_sum, max). La idea es combinar lo mejor de dos mundos: la extracción de características espaciales de las redes convolucionales con la eficiencia temporal asíncrona de las SNNs.

<<<<<<< Updated upstream
Para la optimización de hiperparámetros usamos optimización bayesiana con Optuna TPE (Tree-structured Parzen Estimator), ejecutando 100 pruebas por configuración en tres tamaños de red diferentes (100, 200, 400 neuronas). Implementamos un pipeline de preprocesamiento reproducible que incluye: cuantización dinámica por cuantiles expandidos, expansión de etiquetas para compensar el desbalanceo temporal, y segmentación en ventanas de longitud T=250.
=======
La metodología experimental empleó optimización bayesiana con Optuna TPE para la búsqueda sistemática de hiperparámetros, ejecutando 100 trials por configuración en tres escalas de red (100, 200, 400 neuronas). Se implementó un pipeline de preprocesamiento reproducible que incluye cuantización dinámica por cuantiles expandidos, expansión de etiquetas para mitigar el desbalanceo temporal, y segmentación en ventanas de longitud T=250.

El análisis de importancia de hiperparámetros confirma que los parámetros neuronales (threshold, decay) y de plasticidad (nu1, nu2) son los más influyentes. Los parámetros convolucionales (kernel\_size, sigma) vienen después, lo que valida que la dinámica neuronal LIF juega un papel clave en el rendimiento del modelo.

Las contribuciones principales del trabajo son: (1) una arquitectura híbrida SNN-CNN que se puede optimizar automáticamente, (2) un pipeline de preprocesamiento reproducible adaptado a las características de las SNNs, (3) evidencia empírica de que la hibridación mejora notablemente el rendimiento en datasets desbalanceados, y (4) una metodología de evaluación comparativa que puede servir de base para futuros trabajos en el área.

Este trabajo muestra el potencial de las arquitecturas híbridas SNN-CNN para aplicaciones de detección de anomalías. Ofrecen un buen equilibrio entre rendimiento y eficiencia computacional, lo que las posiciona como una alternativa viable para aplicaciones de tiempo real en entornos con restricciones energéticas.

\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
\label{chap:resumen}

Anomaly detection in time series is a complex problem that affects many industrial sectors, from computer network monitoring to predictive maintenance of critical infrastructures. Traditional methods work well, but they have significant limitations when it comes to energy efficiency and scalability, especially in edge computing applications and resource-constrained devices.

<<<<<<< Updated upstream
This Master's Thesis tackles the development and optimization of a hybrid SNN-CNN (Spiking Neural Network - Convolutional Neural Network) architecture for time series anomaly detection. The focus is on computational sustainability and energy efficiency. Spiking Neural Networks (SNNs) are interesting because they better emulate how biological brains work, and theoretically they can be more energy-efficient thanks to the sparse nature of discrete spikes.
=======
This Master's Thesis presents the development and optimization of a hybrid SNN-CNN architecture for time series anomaly detection, with special emphasis on computational sustainability and energy efficiency. SNNs emerge as a promising paradigm that more faithfully emulates biological brain functioning, offering theoretical advantages in energy efficiency through the inherent sparsity of discrete spikes.
>>>>>>> Stashed changes

The proposed solution starts with a base SNN architecture (A--B) and adds an optimizable convolutional layer (A--B--C) that works with different parametrizable kernels (gaussian, laplacian, mexican hat, box) and various processing modes (direct, weighted\_sum, max). The idea is to combine the best of both worlds: spatial feature extraction from convolutional networks with the asynchronous temporal efficiency of SNNs.

<<<<<<< Updated upstream
For hyperparameter optimization we used Bayesian optimization with Optuna TPE (Tree-structured Parzen Estimator), running 100 trials per configuration across three different network sizes (100, 200, 400 neurons). We implemented a reproducible preprocessing pipeline that includes: dynamic quantization by expanded quantiles, label expansion to handle temporal imbalance, and segmentation into windows of length T=250.
=======
The experimental methodology employed Bayesian optimization with Optuna TPE for systematic hyperparameter search, executing 100 trials per configuration across three network scales (100, 200, 400 neurons). A reproducible preprocessing pipeline was implemented including dynamic quantization by expanded quantiles, label expansion to mitigate temporal imbalance, and segmentation into windows of length T=250.
>>>>>>> Stashed changes

We tested the architecture with two quite different public datasets: IOPS (highly imbalanced, only 1.92\% anomalies) and CalIt2 (more balanced, with 24.80\% anomalies). Results show that the hybrid architecture improves considerably over the base SNN model: 4.6x in IOPS (F1=0.277 vs 0.060) and 1.7x in CalIt2 (F1=0.417 vs 0.239).

When we compare with state-of-the-art models (TSFEDL), we see that traditional deep learning methods still have better absolute performance (F1=0.436 vs 0.277 in IOPS, F1=0.704 vs 0.417 in CalIt2). However, our hybrid SNN-CNN architecture considerably reduces that gap while maintaining the theoretical energy efficiency advantages of SNNs. An interesting finding: experiments show that automatic optimization consistently favors Mexican hat and Gaussian kernels with direct processing, suggesting that spatial smoothing works better than edge detection in these cases.

Hyperparameter importance analysis confirms that neural parameters (threshold, decay) and plasticity parameters (nu1, nu2) are the most influential. Convolutional parameters (kernel\_size, sigma) come next, which validates that LIF neural dynamics play a key role in model performance.

The main contributions of this work include: (1) an automatically optimizable hybrid SNN-CNN architecture, (2) a reproducible preprocessing pipeline adapted to SNN characteristics, (3) empirical evidence that hybridization notably improves performance on imbalanced datasets, and (4) a comparative evaluation methodology that can serve as a foundation for future work in the area.

This work shows the potential of hybrid SNN-CNN architectures for anomaly detection applications. They offer a good balance between performance and computational efficiency, which positions them as a viable alternative for real-time applications in energy-constrained environments.