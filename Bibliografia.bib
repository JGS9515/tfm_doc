%2.1 Motivación
%[1]
@inproceedings{cherdo_time_2023,
	title = {Time series prediction and anomaly detection with recurrent spiking neural networks},
	url = {https://ieeexplore.ieee.org/document/10191614},
	doi = {10.1109/IJCNN54540.2023.10191614},
	abstract = {In the recent years, Spiking Neural Networks have gain much attention from the research community. They can now be trained using the powerful gradient descent and have drifted from the neuroscience to the Machine Learning community. An abundant literature shows that they can perform well on classical Artificial Intelligence tasks such as image or signal classification while consuming less energy than state-of-the-art models like Convolutional Neural Networks. Yet, there is very little work about their performance on unsupervised anomaly detection and time-series prediction. Indeed, the processing of such temporal data requires different encoding and decoding mechanisms and rises questions about their capacity to model a dynamical signal with long term temporal dependencies. In this paper, we propose for the first time a Sparse Recurrent Spiking Neural Network with specific encoding and decoding mechanisms to successfully predict time-series and do Unsupervised Anomaly Detection. We also provide a framework to describe in detail our model computational costs and fairly compare them with state-of-the-art models. Despite improvable performances, we show that our model perform well on these tasks and open a door for further studies of such applications for Spiking Neural Networks.},
	eventtitle = {2023 International Joint Conference on Neural Networks ({IJCNN})},
	pages = {1--10},
	booktitle = {2023 International Joint Conference on Neural Networks ({IJCNN})},
	author = {Cherdo, Yann and Miramond, Benoit and Pegatoquet, Alain},
	urldate = {2025-06-18},
	date = {2023-06},
	note = {{ISSN}: 2161-4407},
	keywords = {{CNN}, Computational modeling, Decoding, Encoding, {LSTM}, Machine learning, Neuroscience, Pattern classification, {RNN}, Spiking Neural Networks, Surro-gate Gradient Descent, Time series analysis, Unsupervised Anomaly detection, time-series prediction},
}
%[2]
@inproceedings{kshirasagar_auditory_2024,
	title = {Auditory Anomaly Detection using Recurrent Spiking Neural Networks},
	url = {https://ieeexplore.ieee.org/document/10595878},
	doi = {10.1109/AICAS59952.2024.10595878},
	abstract = {Brain-inspired networks promise capabilities of achieving high computational efficacy with low energy footprint. Auditory perception systems are resource constrained when deployed on low power edge {AI} devices. Hence, we employ spiking neural networks ({SNNs}) for auditory scene analysis, specifically targeting temporal detection of anomaly cues particularly siren sounds. We generate artificial audio sequences from a publicly available dataset containing various siren and noise sounds. We train small-scale recurrent {SNNs} with leaky-integrate-and-fire ({LIF}) neurons in the hidden layer and achieve accurate predictions with precious few parameters. Further, we provide a baseline for conventional {RNNs} of similar network topology on the same task. With comparable accuracy, reduced parameter, and sparse spiking activity in hidden layer in contrast to conventional methods, we found bio-inspired approach realized using {SNNs} to be promising in solving the time-series auditory anomaly detection task.},
	eventtitle = {2024 {IEEE} 6th International Conference on {AI} Circuits and Systems ({AICAS})},
	pages = {278--281},
	booktitle = {2024 {IEEE} 6th International Conference on {AI} Circuits and Systems ({AICAS})},
	author = {Kshirasagar, Shreya and Cramer, Benjamin and Guntoro, Andre and Mayr, Christian},
	urldate = {2025-06-18},
	date = {2024-04},
	note = {{ISSN}: 2834-9857},
	keywords = {Accuracy, Image analysis, Network topology, Neuromorphics, Neurons, Noise, Spiking neural networks, anomaly detection, auditory perception, brain-inspired computing, siren detection, spiking neural networks},
}
%[3]
@article{plummer_2d_2025,
	title = {2D Spintronics for Neuromorphic Computing with Scalability and Energy Efficiency},
	volume = {15},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9268},
	url = {https://www.mdpi.com/2079-9268/15/2/16},
	doi = {10.3390/jlpea15020016},
	abstract = {The demand for computing power has been growing exponentially with the rise of artificial intelligence ({AI}), machine learning, and the Internet of Things ({IoT}). This growth requires unconventional computing primitives that prioritize energy efficiency, while also addressing the critical need for scalability. Neuromorphic computing, inspired by the biological brain, offers a transformative paradigm for addressing these challenges. This review paper provides an overview of advancements in 2D spintronics and device architectures designed for neuromorphic applications, with a focus on techniques such as spin-orbit torque, magnetic tunnel junctions, and skyrmions. Emerging van der Waals materials like {CrI}3, Fe3GaTe2, and graphene-based heterostructures have demonstrated unparalleled potential for integrating memory and logic at the atomic scale. This work highlights technologies with ultra-low energy consumption (0.14 {fJ}/operation), high switching speeds (sub-nanosecond), and scalability to sub-20 nm footprints. It covers key material innovations and the role of spintronic effects in enabling compact, energy-efficient neuromorphic systems, providing a foundation for advancing scalable, next-generation computing architectures.},
	pages = {16},
	number = {2},
	journaltitle = {Journal of Low Power Electronics and Applications},
	author = {Plummer, Douglas Z. and D’Alessandro, Emily and Burrowes, Aidan and Fleischer, Joshua and Heard, Alexander M. and Wu, Yingying},
	urldate = {2025-06-18},
	date = {2025-06},
	langid = {english},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {2D spintronics, neuromorphic hardware, nonvolatile devices},
}
%[4]
@misc{lv_efficient_2024,
	title = {Efficient and Effective Time-Series Forecasting with Spiking Neural Networks},
	url = {http://arxiv.org/abs/2402.01533},
	doi = {10.48550/arXiv.2402.01533},
	abstract = {Spiking neural networks ({SNNs}), inspired by the spiking behavior of biological neurons, provide a unique pathway for capturing the intricacies of temporal data. However, applying {SNNs} to time-series forecasting is challenging due to difficulties in effective temporal alignment, complexities in encoding processes, and the absence of standardized guidelines for model selection. In this paper, we propose a framework for {SNNs} in time-series forecasting tasks, leveraging the efficiency of spiking neurons in processing temporal information. Through a series of experiments, we demonstrate that our proposed {SNN}-based approaches achieve comparable or superior results to traditional time-series forecasting methods on diverse benchmarks with much less energy consumption. Furthermore, we conduct detailed analysis experiments to assess the {SNN}'s capacity to capture temporal dependencies within time-series data, offering valuable insights into its nuanced strengths and effectiveness in modeling the intricate dynamics of temporal data. Our study contributes to the expanding field of {SNNs} and offers a promising alternative for time-series forecasting tasks, presenting a pathway for the development of more biologically inspired and temporally aware forecasting models. Our code is available at https://github.com/microsoft/{SeqSNN}.},
	number = {{arXiv}:2402.01533},
	publisher = {{arXiv}},
	author = {Lv, Changze and Wang, Yansen and Han, Dongqi and Zheng, Xiaoqing and Huang, Xuanjing and Li, Dongsheng},
	urldate = {2025-06-18},
	date = {2024-05-29},
	eprinttype = {arxiv},
	eprint = {2402.01533 [cs]},
	keywords = {Computer Science - Neural and Evolutionary Computing},
}
%[5]
@article{yusob_anomaly_2018,
	title = {Anomaly Detection in Time Series Data Using Spiking Neural Network},
	volume = {24},
	issn = {1936-6612},
	url = {http://www.ingentaconnect.com/content/10.1166/asl.2018.12980},
	doi = {10.1166/asl.2018.12980},
	abstract = {One of the crucial issues in anomaly detection problems is identifying abnormal patterns in time series data that contains noise and in unstructured form. In order to deal with this problem, a good detector is needed with a capability to learn the complex features in the datasets and extract useful information to distinguish normal and abnormal patterns in the datasets. This study exploits the features of Spiking Neural Network ({SNN}) to generate potential neurons through its learning. These neurons will spike whenever it detects abnormal pattern in the data. The proposed method is consisting of three stages: 1) initializing the weight values using rank order method; 2) representing the real input data into spike values using Gaussian Receptive Fields; and 3) identifying the firing nodes that indicate the abnormal data. We applied the proposed technique to selected data with anomalies from time series datasets. Experimental results show that the proposed technique is capable of detecting the anomalies in the datasets with reasonable False Alarm Rate.},
	pages = {7572--7576},
	number = {10},
	journaltitle = {Advanced Science Letters},
	shortjournal = {adv sci lett},
	author = {Yusob, Bariah and Mustaffa, Zuriani and Sulaiman, Junaida},
	urldate = {2025-06-18},
	date = {2018-10-01},
	langid = {english},
}
%[6]
@article{basler_unsupervised_2022,
	title = {Unsupervised anomaly detection in multivariate time series with online evolving spiking neural networks},
	volume = {111},
	issn = {0885-6125, 1573-0565},
	url = {https://link.springer.com/10.1007/s10994-022-06129-4},
	doi = {10.1007/s10994-022-06129-4},
	abstract = {Abstract
            With the increasing demand for digital products, processes and services the research area of automatic detection of signal outliers in streaming data has gained a lot of attention. The range of possible applications for this kind of algorithms is versatile and ranges from the monitoring of digital machinery and predictive maintenance up to applications in analyzing big data healthcare sensor data. In this paper we present a method for detecting anomalies in streaming multivariate times series by using an adapted evolving Spiking Neural Network. As the main components of this work we contribute (1) an alternative rank-order-based learning algorithm which uses the precise times of the incoming spikes for adjusting the synaptic weights, (2) an adapted, realtime-capable and efficient encoding technique for multivariate data based on multi-dimensional Gaussian Receptive Fields and (3) a continuous outlier scoring function for an improved interpretability of the classifications. Spiking neural networks are extremely efficient when it comes to process time dependent information. We demonstrate the effectiveness of our model on a synthetic dataset based on the Numenta Anomaly Benchmark with various anomaly types. We compare our algorithm to other streaming anomaly detecting algorithms and can prove that our algorithm performs better in detecting anomalies while demanding less computational resources for processing high dimensional data.},
	pages = {1377--1408},
	number = {4},
	journaltitle = {Machine Learning},
	shortjournal = {Mach Learn},
	author = {Bäßler, Dennis and Kortus, Tobias and Gühring, Gabriele},
	urldate = {2025-06-18},
	date = {2022-04},
	langid = {english},
}

@online{Talent.com_2024,
  author = {{Talent.com}},
  title = {Salario},
  url = {https://es.talent.com/salary?job=data},
  urldate = {2024-08-16}, % Reemplaza con la fecha de acceso actual
  year = {2024},
}

%3.2.1 Métodos Iniciales de Control Estadístico de Procesos
%[7]
@book{shewhart_economic_1931,
	location = {Oxford, England},
	title = {Economic control of quality of manufactured product},
	series = {Economic control of quality of manufactured product},
	pagetotal = {515},
	publisher = {Van Nostrand},
	author = {Shewhart, W. A.},
	date = {1931},
	note = {Pages: 515},
}
%[8]
@article{page_continuous_1954,
	title = {Continuous Inspection Schemes},
	volume = {41},
	issn = {0006-3444},
	url = {https://www.jstor.org/stable/2333009},
	doi = {10.2307/2333009},
	pages = {100--115},
	number = {1},
	journaltitle = {Biometrika},
	author = {Page, E. S.},
	urldate = {2025-06-18},
	date = {1954},
	note = {Publisher: [Oxford University Press, Biometrika Trust]},
}
%[9]
@inproceedings{gualandi_worst-case_2023,
	title = {Worst-Case Impact Assessment of Multi-Alarm Stealth Attacks Against Control Systems with {CUSUM}-Based Anomaly Detection},
	url = {https://ieeexplore.ieee.org/document/10336027},
	doi = {10.1109/ACSOS58161.2023.00029},
	abstract = {Manipulating sensor data can deceive cyber-physical systems ({CPSs}), leading to hazardous conditions in physical plants. An Anomaly Detection System ({ADS}) like {CUSUM} detects ongoing attacks by comparing sensor signals with those generated by a model. However, physics-based methods are thresholdbased, which can result in both false positives and undetectable attacks. This can lead to undetected attacks impacting the system state and potentially causing large deviations from the desired behavior. In this paper, we introduce a metric called transparency that uniquely quantifies the effectiveness of an {ADS} in terms of its ability to prevent state deviation. While existing research focuses on designing optimal zero-alarm stealth attacks, we address the challenge of detecting more sophisticated multi-alarm attacks that generate alarms at a rate comparable to the system noise. Through our analysis, we identify the conditions that require the inclusion of multi-alarm scenarios in worst-case impact assessments. We also propose an optimization problem designed to identify multi-alarm attacks by relaxing the constraints of a zero-alarm attack problem. Our findings reveal that multialarm attacks can cause a more significant state deviation than zero-alarm attacks, emphasizing their critical importance in the security analysis of control systems.},
	eventtitle = {2023 {IEEE} International Conference on Autonomic Computing and Self-Organizing Systems ({ACSOS})},
	pages = {117--126},
	booktitle = {2023 {IEEE} International Conference on Autonomic Computing and Self-Organizing Systems ({ACSOS})},
	author = {Gualandi, Gabriele and Papadopoulos, Alessandro V.},
	urldate = {2025-06-18},
	date = {2023-09},
	keywords = {Control systems, Cyber-physical systems, Distributed computing, Heuristic algorithms, Measurement, Security, Timing, control systems, optimization, security},
}
%[10]
@inproceedings{gualandi_optimization-based_2022,
	title = {Optimization-based attack against control systems with {CUSUM}-based anomaly detection},
	url = {https://ieeexplore.ieee.org/document/9837192},
	doi = {10.1109/MED54222.2022.9837192},
	abstract = {Security attacks on sensor data can deceive a control system and force the physical plant to reach an unwanted and potentially dangerous state. Therefore, attack detection mechanisms are employed in cyber-physical control systems to detect ongoing attacks, the most prominent one being a threshold-based anomaly detection method called {CUSUM}. Literature defines the maximum impact of stealth attacks as the maximum deviation in the plant’s state that an undetectable attack can introduce, and formulates it as an optimization problem. This paper proposes an optimization-based attack with different saturation models, and it investigates how the attack duration significantly affects the impact of the attack on the state of the plant. We show that more dangerous attacks can be discovered when allowing saturation of the control system actuators. The proposed approach is compared with the geometric attack, showing how longer attack durations can lead to a greater impact of the attack while keeping the attack stealthy.},
	eventtitle = {2022 30th Mediterranean Conference on Control and Automation ({MED})},
	pages = {896--901},
	booktitle = {2022 30th Mediterranean Conference on Control and Automation ({MED})},
	author = {Gualandi, Gabriele and Maggio, Martina and Vittorio Papadopoulos, Alessandro},
	urldate = {2025-06-18},
	date = {2022-06},
	note = {{ISSN}: 2473-3504},
	keywords = {Actuators, Anomaly detection, Automation, Control systems, Force, Optimization, Security},
}
%3.2.2 Técnicas avanzadas de descomposición estadística
%[11]
@article{morissette_k-means_2013,
	title = {The k-means clustering technique: General considerations and implementation in Mathematica},
	volume = {9},
	issn = {1913-4126},
	url = {http://www.tqmp.org/RegularArticles/vol09-1/p015},
	doi = {10.20982/tqmp.09.1.p015},
	shorttitle = {The k-means clustering technique},
	pages = {15--24},
	number = {1},
	journaltitle = {Tutorials in Quantitative Methods for Psychology},
	shortjournal = {{TQMP}},
	author = {Morissette, Laurence and Chartier, Sylvain},
	urldate = {2025-06-18},
	date = {2013-02-01},
	langid = {english},
}
%[12]
@article{cleveland_stl_1990,
	title = {{STL} : A seasonal-trend decomposition procedure based on loess},
	volume = {6},
	url = {https://cir.nii.ac.jp/crid/1571417124982951296},
	shorttitle = {{STL}},
	pages = {3--73},
	journaltitle = {J Off Stat},
	author = {{CLEVELAND}, {RB}},
	urldate = {2025-06-18},
	date = {1990},
}
%[13]
@article{hafen_syndromic_2009,
	title = {Syndromic surveillance: {STL} for modeling, visualizing, and monitoring disease counts},
	volume = {9},
	issn = {1472-6947},
	url = {https://doi.org/10.1186/1472-6947-9-21},
	doi = {10.1186/1472-6947-9-21},
	shorttitle = {Syndromic surveillance},
	abstract = {Public health surveillance is the monitoring of data to detect and quantify unusual health events. Monitoring pre-diagnostic data, such as emergency department ({ED}) patient chief complaints, enables rapid detection of disease outbreaks. There are many sources of variation in such data; statistical methods need to accurately model them as a basis for timely and accurate disease outbreak methods.},
	pages = {21},
	number = {1},
	journaltitle = {{BMC} Medical Informatics and Decision Making},
	shortjournal = {{BMC} Medical Informatics and Decision Making},
	author = {Hafen, Ryan P. and Anderson, David E. and Cleveland, William S. and Maciejewski, Ross and Ebert, David S. and Abusalah, Ahmad and Yakout, Mohamed and Ouzzani, Mourad and Grannis, Shaun J.},
	urldate = {2025-06-18},
	date = {2009-04-21},
	keywords = {Count Time Series, Generalize Linear Model, Outbreak Detection, Poisson Random Variable, Syndromic Surveillance},
}

%3.3.1 Fundamentos de redes neuronales y métodos basados en reconstrucción
%[14]
@article{hinton_reducing_2006,
	title = {Reducing the Dimensionality of Data with Neural Networks},
	volume = {313},
	url = {https://www.science.org/doi/10.1126/science.1127647},
	doi = {10.1126/science.1127647},
	abstract = {High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such “autoencoder” networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.},
	pages = {504--507},
	number = {5786},
	journaltitle = {Science},
	author = {Hinton, G. E. and Salakhutdinov, R. R.},
	urldate = {2025-06-18},
	date = {2006-07-28},
	note = {Publisher: American Association for the Advancement of Science},
}
%[15]
@article{hochreiter_long_1997,
	title = {Long Short-Term Memory},
	volume = {9},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1997.9.8.1735},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory ({LSTM}). Truncating the gradient where this does not do harm, {LSTM} can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. {LSTM} is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, {LSTM} leads to many more successful runs, and learns much faster. {LSTM} also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	pages = {1735--1780},
	number = {8},
	journaltitle = {Neural Computation},
	shortjournal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	urldate = {2025-06-18},
	date = {1997-11-15},
}
%[16]
@inproceedings{xia_novel_2024,
	title = {A Novel Time Series Approach to Anomaly Detection and Correction for Complex Blockchain Transaction Networks},
	url = {https://ieeexplore.ieee.org/document/10945130},
	doi = {10.1109/TrustCom63139.2024.00106},
	abstract = {The rapid rise in blockchain technology’s popularity has prompted numerous models to analyze patterns and detect anomalies in blockchain networks based on transaction history. However, most existing studies overlook transactions’ dynamic, nonlinear, and time-variant nature in a time series context. This paper introduces an innovative methodology for enhancing blockchain network performance through advanced time series analysis, anomaly detection, and correction. We propose a hybrid deep learning model integrating Long Short-Term Memory ({LSTM}) networks, Multi-Head Attention ({MHA}), and Fully Connected Network ({FCN}) layers to predict transaction volumes in blockchain networks. The {LSTM} network captures both short-term and long-term dependencies in blockchain time series data, while the {MHA} mechanism focuses on relevant input sequence segments. {FCN} layers perform final feature processing and map the output to predicted transaction volumes. To address overfitting, a Dropout layer is added between the {FCN} layers. Anomalies are identified using Gaussian Mixture Models ({GMM}) and corrected via Gaussian Process Regression ({GPR}). Applied to real-world blockchain transaction datasets, our methodology demonstrates superior efficacy in detecting and correcting anomalies, yielding a more accurate representation of the network’s true behavior. This leads to improved estimates of average and peak throughput and network volatility.},
	eventtitle = {2024 {IEEE} 23rd International Conference on Trust, Security and Privacy in Computing and Communications ({TrustCom})},
	pages = {674--682},
	booktitle = {2024 {IEEE} 23rd International Conference on Trust, Security and Privacy in Computing and Communications ({TrustCom})},
	author = {Xia, Qi and Ansu, Badjie and Gao, Jianbin and Grace, Mupoyi Ntuala and Xia, Hu and Amankona, Obiri Isaac},
	urldate = {2025-06-18},
	date = {2024-12},
	note = {{ISSN}: 2324-9013},
	keywords = {Anomaly Correction, Anomaly Detection, Anomaly detection, Blockchain Analytics, Blockchains, Cryptocurrency, Deep Learning for Cryptocurrencies, Deep learning, Gaussian Process Regression, Long short term memory, Network Performance, Scalability, Security, Standards, Throughput, Time Series Analysis, Time series analysis},
}
%3.3.2 Arquitecturas avanzadas de aprendizaje profundo
%[17]
@misc{kingma_auto-encoding_2022-1,
	title = {Auto-Encoding Variational Bayes},
	url = {http://arxiv.org/abs/1312.6114},
	doi = {10.48550/arXiv.1312.6114},
	abstract = {How can we perform efﬁcient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efﬁcient by ﬁtting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reﬂected in experimental results.},
	number = {{arXiv}:1312.6114},
	publisher = {{arXiv}},
	author = {Kingma, Diederik P. and Welling, Max},
	urldate = {2025-06-18},
	date = {2022-12-10},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1312.6114 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}
%[18]
@article{zhang_rethinking_2024,
	title = {Rethinking Robust Multivariate Time Series Anomaly Detection: A Hierarchical Spatio-Temporal Variational Perspective},
	volume = {36},
	issn = {1558-2191},
	url = {https://ieeexplore.ieee.org/document/10689345},
	doi = {10.1109/TKDE.2024.3466291},
	shorttitle = {Rethinking Robust Multivariate Time Series Anomaly Detection},
	abstract = {The robust multivariate time series anomaly detection can facilitate intelligent decisions and timely maintenance in various kinds of monitor systems. However, the robustness is highly restricted by the stochasticity in multivariate time series, which is summarized as temporal stochasticity and spatial stochasticity specifically. In this paper, we explicitly model the temporal stochasticity variables and the latent graph relationship variables into a unified graphical framework, which can achieve better robustness to dynamicity from both the spatial and temporal perspective. First, within the spatial encoder, every connection exists or not is modeled as a binary stochastic variable, and the graph structure can be learnt automatically. Then, the temporal encoder would embed the highly structured time series into latent stochastic variables to capture both complex temporal dependencies and neighbors information. Moreover, we design a history-future combined anomaly score mechanism with both reconstruction decoder and forecasting decoder to improve the anomaly detection performance. By weighting the historical anomaly factor, the future anomaly factor, and the prediction error of current timestamp, the anomaly detection at current timestamp could be more sensitive to anomaly detection. Finally, extensive experiments on three publicly available anomaly detection datasets demonstrate our proposed method can achieve the best performance in terms of recall and F1 compared with state-of-the-arts baselines.},
	pages = {9136--9149},
	number = {12},
	journaltitle = {{IEEE} Transactions on Knowledge and Data Engineering},
	author = {Zhang, Xiao and Xu, Shuqing and Chen, Huashan and Chen, Zekai and Zhuang, Fuzhen and Xiong, Hui and Yu, Dongxiao},
	urldate = {2025-06-18},
	date = {2024-12},
	keywords = {Anomaly detection, Data models, Decoding, Predictive models, Robustness, Stochastic processes, Time series analysis, multivariate time series, self-attention, variational autoencoder},
}
%[19]
@misc{yang_h-vgrae_2020,
	title = {H-{VGRAE}: A Hierarchical Stochastic Spatial-Temporal Embedding Method for Robust Anomaly Detection in Dynamic Networks},
	url = {http://arxiv.org/abs/2007.06903},
	doi = {10.48550/arXiv.2007.06903},
	shorttitle = {H-{VGRAE}},
	abstract = {Detecting anomalous edges and nodes in dynamic networks is critical in various areas, such as social media, computer networks, and so on. Recent approaches leverage network embedding technique to learn how to generate node representations for normal training samples and detect anomalies deviated from normal patterns. However, most existing network embedding approaches learn deterministic node representations, which are sensitive to fluctuations of the topology and attributes due to the high flexibility and stochasticity of dynamic networks. In this paper, a stochastic neural network, named by Hierarchical Variational Graph Recurrent Autoencoder (H-{VGRAE}), is proposed to detect anomalies in dynamic networks by the learned robust node representations in the form of random variables. H-{VGRAE} is a semi-supervised model to capture normal patterns in training set by maximizing the likelihood of the adjacency matrix and node attributes via variational inference. Comparing with existing methods, H-{VGRAE} has three main advantages: 1) H-{VGRAE} learns robust node representations through stochasticity modeling and the extraction of multi-scale spatial-temporal features; 2) H-{VGRAE} can be extended to deep structure with the increase of the dynamic network scale; 3) the anomalous edge and node can be located and interpreted from the probabilistic perspective. Extensive experiments on four real-world datasets demonstrate the outperformance of H-{VGRAE} on anomaly detection in dynamic networks compared with state-of-the-art competitors.},
	number = {{arXiv}:2007.06903},
	publisher = {{arXiv}},
	author = {Yang, Chenming and Zhou, Liang and Wen, Hui and Zhou, Zhiheng and Wu, Yue},
	urldate = {2025-06-18},
	date = {2020-07-14},
	eprinttype = {arxiv},
	eprint = {2007.06903 [cs]},
	keywords = {Computer Science - Social and Information Networks},
}
%[20]
@online{noauthor_180703748_nodate,
	title = {[1807.03748] Representation Learning with Contrastive Predictive Coding},
	url = {https://arxiv.org/abs/1807.03748},
	urldate = {2025-06-18},
}
%[21]
@inproceedings{zhang_skip-step_2024,
	title = {Skip-Step Contrastive Predictive Coding for Time Series Anomaly Detection},
	url = {https://ieeexplore.ieee.org/document/10447104},
	doi = {10.1109/ICASSP48485.2024.10447104},
	abstract = {Self-supervised learning ({SSL}) shows impressive performance in many tasks lacking sufficient labels. In this paper, we study {SSL} in time series anomaly detection ({TSAD}) by incorporating the characteristics of time series data. Specifically, we build an anomaly detection algorithm consisting of global pattern learning and local association learning. The global pattern learning module builds encoder and decoder to reconstruct the raw time series data to detect global anomalies. To complement the limitation of the global pattern learning that ignores local associations between anomaly points and their adjacent windows, we design a local association learning module, which leverages contrastive predictive coding ({CPC}) to transform the identification of anomaly points into positive pairs identification. Motivated by the observation that adjusting the distance between the history window and the time point to be detected directly impacts the detection performance in the {CPC} framework, we further propose a skip-step {CPC} scheme in the local association learning module which adjusts the distance for better construction of the positive pairs and detection results. The experimental results show that the proposed algorithm achieves superior performance on {SMD} and {PSM} datasets in comparison with 12 state-of-the-art algorithms.},
	eventtitle = {{ICASSP} 2024 - 2024 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	pages = {7065--7069},
	booktitle = {{ICASSP} 2024 - 2024 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	author = {Zhang, Kexin and Wen, Qingsong and Zhang, Chaoli and Sun, Liang and Liu, Yong},
	urldate = {2025-06-18},
	date = {2024-04},
	note = {{ISSN}: 2379-190X},
	keywords = {Anomaly Detection, Prediction algorithms, Predictive coding, Self-supervised Learning, Signal processing algorithms, Speech coding, Time Series, Time series analysis, Transforms, Windows},
}
%3.4 Métodos de optimización y ajuste de hiperparámetros
%[22]
@online{noauthor_adaptation_nodate,
	title = {Adaptation in Natural and Artificial Systems (John H. Holland) - {ProQuest}},
	url = {https://www.proquest.com/openview/c78067a39019fb29daf134cf5dfbb2d6/1?pq-origsite=gscholar&cbl=30748},
	abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the {ProQuest} Platform.},
	urldate = {2025-06-18},
	langid = {english},
}
%[23]
@inproceedings{snoek_practical_2012,
	title = {Practical Bayesian Optimization of Machine Learning Algorithms},
	url = {https://www.semanticscholar.org/paper/Practical-Bayesian-Optimization-of-Machine-Learning-Snoek-Larochelle/2e2089ae76fe914706e6fa90081a79c8fe01611e},
	abstract = {The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a "black art" requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process ({GP}). We show that certain choices for the nature of the {GP}, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured {SVMs} and convolutional neural networks.},
	eventtitle = {Neural Information Processing Systems},
	author = {Snoek, Jasper and Larochelle, H. and Adams, Ryan P.},
	urldate = {2025-06-18},
	date = {2012-06-13},
}
%[24]
@article{yang_cnts_2023,
	title = {{CNTS}: Cooperative Network for Time Series},
	volume = {11},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10077391},
	doi = {10.1109/ACCESS.2023.3259467},
	shorttitle = {{CNTS}},
	abstract = {The use of deep learning techniques in detecting anomalies in time series data has been an active area of research with a long history of development and a variety of approaches. In particular, reconstruction-based unsupervised anomaly detection methods have gained popularity due to their intuitive assumptions and low computational requirements. However, these methods are often susceptible to outliers and do not effectively model anomalies, leading to suboptimal results. This paper presents a novel approach for unsupervised anomaly detection, called the Cooperative Network Time Series ({CNTS}) approach. The {CNTS} system consists of two components: a detector and a reconstructor. The detector is responsible for directly detecting anomalies, while the reconstructor provides reconstruction information to the detector and updates its learning based on anomalous information received from the detector. The central aspect of {CNTS} is a multi-objective optimization problem, which is solved through a cooperative solution strategy. Experiments on three real-world datasets demonstrate the state-of-the-art performance of {CNTS} and confirm the effectiveness of the detector and reconstructor. The source code for this study is publicly available on {GitHub} (https://github.com/{BomBooooo}/{CNTS}/tree/main).},
	pages = {31941--31950},
	journaltitle = {{IEEE} Access},
	author = {Yang, Jinsheng and Shao, Yuanhai and Li, Chun-Na},
	urldate = {2025-06-18},
	date = {2023},
	keywords = {Anomaly detection, Cooperative systems, Data models, Deep learning, Detectors, Task analysis, Time series analysis, anomaly detection, cooperative network, reconstruction, time series},
}
%3.5. Redes neuronales de impulsos y computación
neuromórfica
%[25]
@article{maass_networks_1997,
	title = {Networks of spiking neurons: The third generation of neural network models},
	volume = {10},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608097000117},
	doi = {10.1016/S0893-6080(97)00011-7},
	shorttitle = {Networks of spiking neurons},
	abstract = {The computational power of formal models for networks of spiking neurons is compared with that of other neural network models based on {McCulloch} Pitts neurons (i.e., threshold gates), respectively, sigmoidal gates. In particular it is shown that networks of spiking neurons are, with regard to the number of neurons that are needed, computationally more powerful than these other neural network models. A concrete biologically relevant function is exhibited which can be computed by a single spiking neuron (for biologically reasonable values of its parameters), but which requires hundreds of hidden units on a sigmoidal neural net. On the other hand, it is known that any function that can be computed by a small sigmoidal neural net can also be computed by a small network of spiking neurons. This article does not assume prior knowledge about spiking neurons, and it contains an extensive list of references to the currently available literature on computations in networks of spiking neurons and relevant results from neurobiology.},
	pages = {1659--1671},
	number = {9},
	journaltitle = {Neural Networks},
	shortjournal = {Neural Networks},
	author = {Maass, Wolfgang},
	urldate = {2025-06-18},
	date = {1997-12-01},
	keywords = {Computational complexity, Integrate-and-fire neutron, Lower bounds, Sigmoidal neural nets, Spiking neuron},
}
%[26]
@article{markram_history_2011,
	title = {A History of Spike-Timing-Dependent Plasticity},
	volume = {3},
	issn = {1663-3563},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3187646/},
	doi = {10.3389/fnsyn.2011.00004},
	abstract = {How learning and memory is achieved in the brain is a central question in neuroscience. Key to today’s research into information storage in the brain is the concept of synaptic plasticity, a notion that has been heavily influenced by Hebb's () postulate. Hebb conjectured that repeatedly and persistently co-active cells should increase connective strength among populations of interconnected neurons as a means of storing a memory trace, also known as an engram. Hebb certainly was not the first to make such a conjecture, as we show in this history. Nevertheless, literally thousands of studies into the classical frequency-dependent paradigm of cellular learning rules were directly inspired by the Hebbian postulate. But in more recent years, a novel concept in cellular learning has emerged, where temporal order instead of frequency is emphasized. This new learning paradigm – known as spike-timing-dependent plasticity ({STDP}) – has rapidly gained tremendous interest, perhaps because of its combination of elegant simplicity, biological plausibility, and computational power. But what are the roots of today’s {STDP} concept? Here, we discuss several centuries of diverse thinking, beginning with philosophers such as Aristotle, Locke, and Ribot, traversing, e.g., Lugaro’s plasticità and Rosenblatt’s perceptron, and culminating with the discovery of {STDP}. We highlight interactions between theoretical and experimental fields, showing how discoveries sometimes occurred in parallel, seemingly without much knowledge of the other field, and sometimes via concrete back-and-forth communication. We point out where the future directions may lie, which includes interneuron {STDP}, the functional impact of {STDP}, its mechanisms and its neuromodulatory regulation, and the linking of {STDP} to the developmental formation and continuous plasticity of neuronal networks.},
	pages = {4},
	journaltitle = {Frontiers in Synaptic Neuroscience},
	shortjournal = {Front Synaptic Neurosci},
	author = {Markram, Henry and Gerstner, Wulfram and Sjöström, Per Jesper},
	urldate = {2025-06-18},
	date = {2011-08-29},
	pmid = {22007168},
	pmcid = {PMC3187646},
}
%[27]
@article{indiveri_neuromorphic_2011,
	title = {Neuromorphic Silicon Neuron Circuits},
	volume = {5},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2011.00073/full},
	doi = {10.3389/fnins.2011.00073},
	abstract = {Hardware implementations of spiking neurons can be extremely useful for a large variety of applications, ranging from high-speed modeling of large-scale neural systems to real-time behaving systems, to bidirectional brain-machine interfaces. The specific circuit solutions used to implement silicon neurons depend on the application requirements. In this paper we describe the most common building blocks and techniques used to implement these circuits, and present an overview of a wide range of neuromorphic silicon neurons, which implement different computational models, ranging from biophysically realistic and conductance based Hodgkin-Huxley models to bi-dimensional generalized adaptive Integrate and Fire models. We compare the different design methodologies used for each silicon neuron design described, and demonstrate their features with experimental results, measured from a wide range of fabricated {VLSI} chips.},
	journaltitle = {Frontiers in Neuroscience},
	shortjournal = {Front. Neurosci.},
	author = {Indiveri, Giacomo and Linares-Barranco, Bernabe and Hamilton, Tara Julia and van Schaik, André and Etienne-Cummings, Ralph and Delbruck, Tobi and Liu, Shih-Chii and Dudek, Piotr and Häfliger, Philipp and Renaud, Sylvie and Schemmel, Johannes and Cauwenberghs, Gert and Arthur, John and Hynna, Kai and Folowosele, Fopefolu and Saïghi, Sylvain and Serrano-Gotarredona, Teresa and Wijekoon, Jayawan and Wang, Yingxue and Boahen, Kwabena},
	urldate = {2025-06-18},
	date = {2011-05-31},
	note = {Publisher: Frontiers},
	keywords = {adaptive exponential, analog {VLSI}, circuit, conductance based, integrate and fire, log-domain, spiking, subthreshold},
}
%[28]
@article{lee_robust_2022,
	title = {Robust Audio Anomaly Detection},
	url = {https://www.semanticscholar.org/paper/Robust-Audio-Anomaly-Detection-Lee-Helwani/ab7674da4ca2735c2ec76b283290e8c51495d4fb},
	abstract = {We propose an outlier robust multivariate time series model which can be used for detecting previously unseen anomalous sounds based on noisy training data. The presented approach doesn't assume the presence of labeled anomalies in the training dataset and uses a novel deep neural network architecture to learn the temporal dynamics of the multivariate time series at multiple resolutions while being robust to contaminations in the training dataset. The temporal dynamics are modeled using recurrent layers augmented with attention mechanism. These recurrent layers are built on top of convolutional layers allowing the network to extract features at multiple resolutions. The output of the network is an outlier robust probability density function modeling the conditional probability of future samples given the time series history. State-of-the-art approaches using other multiresolution architectures are contrasted with our proposed approach. We validate our solution using publicly available machine sound datasets. We demonstrate the effectiveness of our approach in anomaly detection by comparing against several state-of-the-art models.},
	journaltitle = {{ArXiv}},
	author = {Lee, Wo Jae and Helwani, Karim and Krishnaswamy, A. and Tenneti, S.},
	urldate = {2025-06-18},
	date = {2022-02-03},
}
%[29]
@inproceedings{sanaullah_hybrid_2024,
	title = {A Hybrid Spiking-Convolutional Neural Network Approach for Advancing Machine Learning Models},
	url = {https://proceedings.mlr.press/v233/sanaullah24a.html},
	abstract = {In this article, we propose a novel standalone hybrid Spiking-Convolutional Neural Network ({SC}-{NN}) model and test on using image inpainting tasks. Our approach uses the unique capabilities of {SNNs}, such as event-based computation and temporal processing, along with the strong representation learning abilities of {CNNs}, to generate high-quality inpainted images. The model is trained on a custom dataset specifically designed for image inpainting, where missing regions are created using masks. The hybrid model consists of {SNNConv}2d layers and traditional {CNN} layers. The {SNNConv}2d layers implement the leaky integrate-and-fire ({LIF}) neuron model, capturing spiking behavior, while the {CNN} layers capture spatial features. In this study, a mean squared error ({MSE}) loss function demonstrates the training process, where a training loss value of 0.015, indicates accurate performance on the training set and the model achieved a validation loss value as low as 0.0017 on the testing set. Furthermore, extensive experimental results demonstrate state-of-the-art performance, showcasing the potential of integrating temporal dynamics and feature extraction in a single network for image inpainting.},
	eventtitle = {Northern Lights Deep Learning Conference},
	pages = {220--227},
	booktitle = {Proceedings of the 5th Northern Lights Deep Learning Conference (\{{NLDL}\})},
	publisher = {{PMLR}},
	author = {Sanaullah, Sanaullah},
	urldate = {2025-06-18},
	date = {2024-01-23},
	langid = {english},
	note = {{ISSN}: 2640-3498},
}
%[30]
@article{liu_sparsity-aware_2024,
	title = {Sparsity-Aware In-Memory Neuromorphic Computing Unit With Configurable Topology of Hybrid Spiking and Artificial Neural Network},
	volume = {71},
	issn = {1558-0806},
	url = {https://ieeexplore.ieee.org/document/10478711},
	doi = {10.1109/TCSI.2024.3377700},
	abstract = {Spiking neural networks ({SNNs}) have shown great potential in achieving high energy efficiency and low power consumption compared to artificial neural networks ({ANNs}). However, there remains a significant accuracy gap between {SNNs} and {ANNs}. To address this issue, we present an in-memory neuromorphic computing ({IMNC}) chip that supports hybrid spiking/artificial neural networks (S/{ANNs}) and sparsity-aware data flows. With the {IMNC} chip, we aim to improve inference accuracy while simultaneously achieving high energy efficiency through optimization at the algorithm, architecture, and circuit levels. First, at the algorithm level, we note that {SNNs} extract temporal features from input spikes using time-domain convolution operations. Based on this insight, we efficiently utilize leaky integrate ({LI}) neurons to hybridize {SNNs} and {ANNs}, thereby improving accuracy while maintaining highly sparse operations. Second, at the architecture level, we design a sparsity-aware architecture that supports a hybrid S/{ANN} topology with varying sparsity. Finally, at the circuit level, we propose a ring-based in-memory computing ({IMC}) macro, whose energy consumption is inversely proportional to the input sparsity, making it ideal for performing energy-efficient multiplication and accumulation ({MAC}) operations in both {SNNs} and {ANNs}. We evaluate the proposed hybrid S/{ANNs} on various classification tasks and demonstrate their stronger classification and generalization ability compared with pure {SNNs}. Notably, our {IMNC} chip, fabricated using 22 nm {CMOS} technology, achieves impressive measured accuracy rates of over 95\% for voice activity detection ({VAD}) and {ECG} anomaly detection. Additionally, our {IMNC} chip demonstrates superior dynamic energy efficiency of 0.43 {pJ} per synaptic operation, outperforming related works.},
	pages = {2660--2673},
	number = {6},
	journaltitle = {{IEEE} Transactions on Circuits and Systems I: Regular Papers},
	author = {Liu, Ying and Chen, Zhiyuan and Zhao, Wentao and Zhao, Tianhao and Jia, Tianyu and Wang, Zhixuan and Huang, Ru and Ye, Le and Ma, Yufei},
	urldate = {2025-06-18},
	date = {2024-06},
	keywords = {Artificial neural networks, Computer architecture, Energy efficiency, Feature extraction, In-memory computing, Micromechanical devices, Neuromorphic engineering, Neurons, Spiking neural networks, Synapses, artificial neural networks, in-memory computing, neuromorphic computing},
}

%3.6 Desarrollo de Benchmarks
%[31]
@inproceedings{lavin_evaluating_2015,
	title = {Evaluating Real-Time Anomaly Detection Algorithms – The Numenta Anomaly Benchmark},
	url = {https://ieeexplore.ieee.org/document/7424283},
	doi = {10.1109/ICMLA.2015.141},
	abstract = {Much of the world's data is streaming, time-series data, where anomalies give significant information in critical situations, examples abound in domains such as finance, {IT}, security, medical, and energy. Yet detecting anomalies in streaming data is a difficult task, requiring detectors to process data in real-time, not batches, and learn while simultaneously making predictions. There are no benchmarks to adequately test and score the efficacy of real-time anomaly detectors. Here we propose the Numenta Anomaly Benchmark ({NAB}), which attempts to provide a controlled and repeatable environment of open-source tools to test and measure anomaly detection algorithms on streaming data. The perfect detector would detect all anomalies as soon as possible, trigger no false alarms, work with real-world time-series data across a variety of domains, and automatically adapt to changing statistics. Rewarding these characteristics is formalized in {NAB}, using a scoring algorithm designed for streaming data. {NAB} evaluates detectors on a benchmark dataset with labeled, real-world time-series data. We present these components, and give results and analyses for several open source, commercially-used algorithms. The goal for {NAB} is to provide a standard, open source framework with which the research community can compare and evaluate different algorithms for detecting anomalies in streaming data.},
	eventtitle = {2015 {IEEE} 14th International Conference on Machine Learning and Applications ({ICMLA})},
	pages = {38--44},
	booktitle = {2015 {IEEE} 14th International Conference on Machine Learning and Applications ({ICMLA})},
	author = {Lavin, Alexander and Ahmad, Subutai},
	urldate = {2025-06-18},
	date = {2015-12},
	keywords = {Algorithm design and analysis, Benchmark testing, Detection algorithms, Detectors, Measurement, Real-time systems, Standards, anomaly detection, benchmarks, streaming data, time-series data},
}
%[32]
@article{wu_current_2023,
	title = {Current Time Series Anomaly Detection Benchmarks are Flawed and are Creating the Illusion of Progress},
	volume = {35},
	issn = {1558-2191},
	url = {https://ieeexplore.ieee.org/document/9537291},
	doi = {10.1109/TKDE.2021.3112126},
	abstract = {Time series anomaly detection has been a perennially important topic in data science, with papers dating back to the 1950s. However, in recent years there has been an explosion of interest in this topic, much of it driven by the success of deep learning in other domains and for other time series tasks. Most of these papers test on one or more of a handful of popular benchmark datasets, created by Yahoo, Numenta, {NASA}, etc. In this work we make a surprising claim. The majority of the individual exemplars in these datasets suffer from one or more of four flaws. Because of these four flaws, we believe that many published comparisons of anomaly detection algorithms may be unreliable, and more importantly, much of the apparent progress in recent years may be illusionary. In addition to demonstrating these claims, with this paper we introduce the {UCR} Time Series Anomaly Archive. We believe that this resource will perform a similar role as the {UCR} Time Series Classification Archive, by providing the community with a benchmark that allows meaningful comparisons between approaches and a meaningful gauge of overall progress.},
	pages = {2421--2429},
	number = {3},
	journaltitle = {{IEEE} Transactions on Knowledge and Data Engineering},
	author = {Wu, Renjie and Keogh, Eamonn J.},
	urldate = {2025-06-18},
	date = {2023-03},
	keywords = {Anomaly detection, Benchmark testing, Codes, Computer science, Deep learning, {NASA}, Time series analysis, benchmark datasets, deep learning, time series analysis},
}
%3.7 Eficiencia Energética en Redes
%[33]
@article{skatchkovsky_bayesian_2022,
	title = {Bayesian continual learning via spiking neural networks},
	volume = {16},
	issn = {1662-5188},
	url = {https://www.frontiersin.org/journals/computational-neuroscience/articles/10.3389/fncom.2022.1037976/full},
	doi = {10.3389/fncom.2022.1037976},
	abstract = {Among the main features of biological intelligence are energy efficiency, capacity for continual adaptation, and risk management via uncertainty quantification. Neuromorphic engineering has been thus far mostly driven by the goal of implementing energy-efficient machines that take inspiration from the time-based computing paradigm of biological brains. In this paper, we take steps toward the design of neuromorphic systems that are capable of adaptation to changing learning tasks, while producing well-calibrated uncertainty quantification estimates. To this end, we derive online learning rules for spiking neural networks ({SNNs}) within a Bayesian continual learning framework. In it, each synaptic weight is represented by parameters that quantify the current epistemic uncertainty resulting from prior knowledge and observed data. The proposed online rules update the distribution parameters in a streaming fashion as data are observed. We instantiate the proposed approach for both real-valued and binary synaptic weights. Experimental results using Intel's Lava platform show the merits of Bayesian over frequentist learning in terms of capacity for adaptation and uncertainty quantification.},
	journaltitle = {Frontiers in Computational Neuroscience},
	shortjournal = {Front. Comput. Neurosci.},
	author = {Skatchkovsky, Nicolas and Jang, Hyeryung and Simeone, Osvaldo},
	urldate = {2025-06-19},
	date = {2022-11-16},
	note = {Publisher: Frontiers},
	keywords = {Bayesian learning, Neuromorphic learning, artificial intelligence, neuromorphic hardware, spiking neural networks},
}
%[34]
@inproceedings{haddad_comparative_2024,
	title = {Comparative Analysis of Off-the-Shelf Methods for Energy Consumption Anomaly Detection},
	url = {https://ieeexplore.ieee.org/document/10553212},
	doi = {10.1109/ICARA60736.2024.10553212},
	abstract = {Research in Deep Neural Networks ({DNNs}) has gained significant attention from industries and academia achieving unprecedented success. However, {DNNs} need large-sized datasets and high computation times. In the field of energy consumption anomaly detection in buildings, {DNNs} methods were recently applied. Nevertheless, It's state of the art main issue is the lack of platforms (Datasets and Frameworks) for reproducing existing solutions results. This may hinder performances comparison between existing off-the-shelf methods. In this paper, we conduct an empirical comparison by benchmarking 15 Off-the-shelf supervised, semi-supervised and unsupervised methods. We conducted extensive experiments to evaluate their Accuracy and F1 score performances, in addition to their training time and inference time. Experiments were conducted on three publicly available annotated datasets. Preliminary results show that Bagging and Boosting methods achieve better performances compared to Neural Networks methods and require less training and inference computation time.},
	eventtitle = {2024 10th International Conference on Automation, Robotics and Applications ({ICARA})},
	pages = {392--396},
	booktitle = {2024 10th International Conference on Automation, Robotics and Applications ({ICARA})},
	author = {Haddad, Hatem and Jerbi, Feres and Smaali, Issam},
	urldate = {2025-06-19},
	date = {2024-02},
	note = {{ISSN}: 2767-7745},
	keywords = {Accuracy, Anomaly detection, Boosting, Energy consumption, Industries, Radio frequency, Training, anomaly detection, energy consumption, machine learning},
}
%[35]
@inproceedings{mali_comparison_2024,
	title = {Comparison of the Statistical and Autoencoder Approach for Anomaly Detection in Big Data},
	url = {https://ieeexplore.ieee.org/document/10689688},
	doi = {10.1109/IBDAP62940.2024.10689688},
	abstract = {This paper compares two anomaly detection methods, comparing the Z-score statistical technique with autoen-coders for big datasets, which are crucial for industries like manufacturing, energy, and transportation to maintain smooth operations and avoid costly disruptions. Autoencoders outperformed Z-score statistical technique in anomaly detection on big datasets, achieving higher precision (0.94), F1-score (0.97), and recall (1.00) compared to Z-score statistical technique. This highlights autoencoders' superior ability to accurately identify anomalies, making them more effective for robust anomaly detection in complex data environments.},
	eventtitle = {2024 5th International Conference on Big Data Analytics and Practices ({IBDAP})},
	pages = {22--25},
	booktitle = {2024 5th International Conference on Big Data Analytics and Practices ({IBDAP})},
	author = {Mali, Barasha},
	urldate = {2025-06-19},
	date = {2024-08},
	keywords = {Big Data, Decision making, Industries, Manufacturing, Measurement, Reliability, Transportation, anomaly, autoencoders, big data, machine learning, statistical techniques},
}
%[36]
@inproceedings{jang_bisnn_2021,
	title = {{BiSNN}: Training Spiking Neural Networks with Binary Weights via Bayesian Learning},
	url = {https://ieeexplore.ieee.org/document/9523415},
	doi = {10.1109/DSLW51110.2021.9523415},
	shorttitle = {{BiSNN}},
	abstract = {Artificial Neural Network ({ANN})-based inference on battery-powered devices can be made more energy-efficient by restricting the synaptic weights to be binary, hence eliminating the need to perform multiplications. An alternative, emerging, approach relies on the use of Spiking Neural Networks ({SNNs}), biologically inspired, dynamic, event-driven models that enhance energy efficiency via the use of binary, sparse, activations. In this paper, an {SNN} model is introduced that combines the benefits of temporally sparse binary activations and of binary weights. Two learning rules are derived, the first based on the combination of straight-through and surrogate gradient techniques, and the second based on a Bayesian paradigm. Experiments validate the performance loss with respect to full-precision implementations, and demonstrate the advantage of the Bayesian paradigm in terms of accuracy and calibration.},
	eventtitle = {2021 {IEEE} Data Science and Learning Workshop ({DSLW})},
	pages = {1--6},
	booktitle = {2021 {IEEE} Data Science and Learning Workshop ({DSLW})},
	author = {Jang, Hyeryung and Skatchkovsky, Nicolas and Simeone, Osvaldo},
	urldate = {2025-06-19},
	date = {2021-06},
	keywords = {Artificial neural networks, Bayesian learning, Biological system modeling, Conferences, Data science, Energy efficiency, Performance evaluation, Spiking Neural Networks, Training, binary weights, calibration},
}
%[37]
@article{maddula_ai-driven_2024,
	title = {{AI}-Driven Neuromorphic Computing for Energy-Efficient Anomaly Detection in {IoT} Networks},
	volume = {8},
	abstract = {The propagation of Internet of Things ({IoT}) networks has led to an increasing need for realtime anomaly detection to ensure system reliability and security. However, traditional deep learning models employed for this task often come with significant energy consumption and latency challenges, particularly when deployed on resourceconstrained edge devices. This research explores the use of neuromorphic computing, specifically spiking neural networks ({SNNs}), to develop an energyefficient anomaly detection system for {IoT} networks. A novel architecture is proposed where {SNNs} operate at the edge, leveraging their event-driven nature to provide ultra-low-power, real-time anomaly detection. The designed system reduces energy consumption and minimizes detection latency, making it suitable for deployment in energy-sensitive {IoT} environments. A comprehensive analysis is conducted, comparing the performance of the neuromorphic model against traditional deep learning approaches, focusing on metrics such as energy efficiency, detection accuracy, and latency. The findings demonstrate that {SNN}-based anomaly detection can significantly enhance the energy efficiency of {IoT} systems while maintaining or even improving detection performance, paving the way for more sustainable and responsive {IoT} deployments.},
	number = {3},
	author = {Maddula, Srujana and Gupta, Himanshu and Basha, Shaik Mohammad Jani},
	date = {2024},
	langid = {english},
}
%[38]
@article{islam_benchmarking_2024,
	title = {Benchmarking Artificial Neural Network Architectures for High-Performance Spiking Neural Networks},
	volume = {24},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/24/4/1329},
	doi = {10.3390/s24041329},
	abstract = {Organizations managing high-performance computing systems face a multitude of challenges, including overarching concerns such as overall energy consumption, microprocessor clock frequency limitations, and the escalating costs associated with chip production. Evidently, processor speeds have plateaued over the last decade, persisting within the range of 2 {GHz} to 5 {GHz}. Scholars assert that brain-inspired computing holds substantial promise for mitigating these challenges. The spiking neural network ({SNN}) particularly stands out for its commendable power efficiency when juxtaposed with conventional design paradigms. Nevertheless, our scrutiny has brought to light several pivotal challenges impeding the seamless implementation of large-scale neural networks ({NNs}) on silicon. These challenges encompass the absence of automated tools, the need for multifaceted domain expertise, and the inadequacy of existing algorithms to efficiently partition and place extensive {SNN} computations onto hardware infrastructure. In this paper, we posit the development of an automated tool flow capable of transmuting any {NN} into an {SNN}. This undertaking involves the creation of a novel graph-partitioning algorithm designed to strategically place {SNNs} on a network-on-chip ({NoC}), thereby paving the way for future energy-efficient and high-performance computing paradigms. The presented methodology showcases its effectiveness by successfully transforming {ANN} architectures into {SNNs} with a marginal average error penalty of merely 2.65\%. The proposed graph-partitioning algorithm enables a 14.22\% decrease in inter-synaptic communication and an 87.58\% reduction in intra-synaptic communication, on average, underscoring the effectiveness of the proposed algorithm in optimizing {NN} communication pathways. Compared to a baseline graph-partitioning algorithm, the proposed approach exhibits an average decrease of 79.74\% in latency and a 14.67\% reduction in energy consumption. Using existing {NoC} tools, the energy-latency product of {SNN} architectures is, on average, 82.71\% lower than that of the baseline architectures.},
	pages = {1329},
	number = {4},
	journaltitle = {Sensors},
	author = {Islam, Riadul and Majurski, Patrick and Kwon, Jun and Sharma, Anurag and Tummala, Sri Ranga Sai Krishna},
	urldate = {2025-06-19},
	date = {2024-01},
	langid = {english},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {{ANN}, {ANN}-to-{SNN} conversion, {CNN}, {NoC}, {SNN}, artificial neural network, convolutional neural network, low energy, network-on-chip, spiking neural network},
}
%[39]
@online{noauthor_optuna_nodate,
	title = {Optuna: The Smarter Way to Optimize Your Machine Learning Models},
	url = {https://www.linkedin.com/pulse/optuna-smarter-way-optimize-your-machine-learning-models-kaushik-unjqc},
	shorttitle = {Optuna},
	abstract = {1. Introduction "Ever feel like you’re stuck in a loop when tuning hyperparameters for your machine learning models? You try different combinations of values, test them, and repeat.},
	urldate = {2025-06-19},
	langid = {english},
}
%[40]
@online{firmin_parallel_2024,
	title = {Parallel Hyperparameter Optimization Of Spiking Neural Network},
	url = {https://arxiv.org/abs/2403.00450v1},
	abstract = {Spiking Neural Networks ({SNN}). {SNNs} are based on a more biologically inspired approach than usual artificial neural networks. Such models are characterized by complex dynamics between neurons and spikes. These are very sensitive to the hyperparameters, making their optimization challenging. To tackle hyperparameter optimization of {SNNs}, we initially extended the signal loss issue of {SNNs} to what we call silent networks. These networks fail to emit enough spikes at their outputs due to mistuned hyperparameters or architecture. Generally, search spaces are heavily restrained, sometimes even discretized, to prevent the sampling of such networks. By defining an early stopping criterion detecting silent networks and by designing specific constraints, we were able to instantiate larger and more flexible search spaces. We applied a constrained Bayesian optimization technique, which was asynchronously parallelized, as the evaluation time of a {SNN} is highly stochastic. Large-scale experiments were carried-out on a multi-{GPU} Petascale architecture. By leveraging silent networks, results show an acceleration of the search, while maintaining good performances of both the optimization algorithm and the best solution obtained. We were able to apply our methodology to two popular training algorithms, known as spike timing dependent plasticity and surrogate gradient. Early detection allowed us to prevent worthless and costly computation, directing the search toward promising hyperparameter combinations. Our methodology could be applied to multi-objective problems, where the spiking activity is often minimized to reduce the energy consumption. In this scenario, it becomes essential to find the delicate frontier between low-spiking and silent networks. Finally, our approach may have implications for neural architecture search, particularly in defining suitable spiking architectures.},
	titleaddon = {{arXiv}.org},
	author = {Firmin, Thomas and Boulet, Pierre and Talbi, El-Ghazali},
	urldate = {2025-06-19},
	date = {2024-03-01},
	langid = {english},
	doi = {10.1016/j.neucom.2024.128483},
}
%[41]
@online{noauthor_efficient_2021,
	title = {Efficient Hyperparameter Optimization with Optuna Framework},
	url = {https://broutonlab.com/blog/efficient-hyperparameter-optimization-with-optuna-framework/},
	abstract = {Hyperparameters optimization is an essential part of machine learning and deep learning projects. Manually selecting the best hyperparameters is not easy. This is the case especially for complex models such as neural networks.},
	titleaddon = {{BroutonLab} Blog},
	urldate = {2025-06-19},
	date = {2021-04-12},
	langid = {english},
}
%[42]
@inproceedings{parsa_bayesian-based_2019,
	location = {Los Angeles, {CA}, {USA}},
	title = {Bayesian-based Hyperparameter Optimization for Spiking Neuromorphic Systems},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-7281-0858-2},
	url = {https://ieeexplore.ieee.org/document/9006383/},
	doi = {10.1109/BigData47090.2019.9006383},
	abstract = {Designing a neuromorphic computing system involves selection of several hyperparameters that not only affect the accuracy of the framework, but also the energy efﬁciency and speed of inference and training. These hyperparameters might be inherent to the training of the spiking neural network ({SNN}), the input/output encoding of the real-world data to spikes, or the underlying neuromorphic hardware. In this work, we present a Bayesian-based hyperparameter optimization approach for spiking neuromorphic systems, and we show how this optimization framework can lead to signiﬁcant improvement in designing accurate neuromorphic computing systems. In particular, we show that this hyperparameter optimization approach can discover the same optimal hyperparameter set for input encoding as a grid search, but with far fewer evaluations and far less time. We also show the impact of hardware-speciﬁc hyperparameters on the performance of the system, and we demonstrate that by optimizing these hyperparameters, we can achieve signiﬁcantly better application performance.},
	eventtitle = {2019 {IEEE} International Conference on Big Data (Big Data)},
	pages = {4472--4478},
	booktitle = {2019 {IEEE} International Conference on Big Data (Big Data)},
	publisher = {{IEEE}},
	author = {Parsa, Maryam and Mitchell, J. Parker and Schuman, Catherine D. and Patton, Robert M. and Potok, Thomas E. and Roy, Kaushik},
	urldate = {2025-06-19},
	date = {2019-12},
	langid = {english},
}



%Preprocesamiento de datos para SNN
@misc{milvus2025anomaly,
  author       = {{Milvus}},
  title        = {What preprocessing techniques are used in anomaly detection?},
  howpublished = {\url{https://milvus.io/ai-quick-reference/what-preprocessing-techniques-are-used-in-anomaly-detection/}},
  year         = {2025},
  note         = {Consultado el 12 de julio de 2025},
}
@misc{UCI_Calit2_2009,
  author       = {{UCI Machine Learning Repository}},
  title        = {Calit2 Building People Counts Data Set},
  year         = {2009},
  url          = {https://archive.ics.uci.edu/dataset/156/calit2+building+people+counts},
  note         = {Accessed: 2025-07-12},
  institution  = {University of California, Irvine, School of Information and Computer Sciences}
}


%Selección de BindsNET como framework de desarrollo
@article{Hazan2018_BindsNET,
  author       = {Hananel Hazan and Daniel J. Saunders and Hassaan Khan and Devdhar Patel and Darpan T. Sanghavi and Hava T. Siegelmann and Robert Kozma},
  title        = {BindsNET: A Machine Learning‑Oriented Spiking Neural Networks Library in Python},
  journal      = {Frontiers in Neuroinformatics},
  volume       = {12},
  pages        = {89},
  year         = {2018},
  doi          = {10.3389/fninf.2018.00089},
  url          = {https://www.frontiersin.org/journals/neuroinformatics/articles/10.3389/fninf.2018.00089/full}
}
@misc{bindsnet_docs,
  author       = {BindsNET Contributors},
  title        = {BindsNET Documentation},
  year         = {2024},
  url          = {https://bindsnet-docs.readthedocs.io/},
  note         = {Accessed: 2025-07-12},
  howpublished = {\url{https://bindsnet-docs.readthedocs.io/}}
}
@misc{deadsnakes2025,
  author       = {{deadsnakes}},
  title        = {deadsnakes GitHub Organization},
  year         = {2025},
  howpublished = {\url{https://github.com/deadsnakes}},
  note         = {Accessed: 2025-07-12}
}
